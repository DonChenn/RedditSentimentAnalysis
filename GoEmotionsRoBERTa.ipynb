{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jnd1coBvmphN"
      },
      "outputs": [],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load goEmotions Dataset and get Sentiment Labels\n",
        "goEmotionsDataset = load_dataset('go_emotions')\n",
        "sentimentLabels = goEmotionsDataset['train'].features['labels'].feature.names"
      ],
      "metadata": {
        "id": "IKzl2AD9nX5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification\n",
        "\n",
        "# Download basic roBERTa model\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    'roberta-base',\n",
        "    num_labels=len(sentimentLabels),\n",
        "    problem_type='multi_label_classification'\n",
        ")"
      ],
      "metadata": {
        "id": "tcESH48Vq9hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert dataset sentiment keys into one hot encoding\n",
        "def one_hot_encode(example):\n",
        "    vector = np.zeros(28, dtype=np.float32)\n",
        "\n",
        "    for label_index in example['labels']:\n",
        "        vector[label_index] = 1.0\n",
        "\n",
        "    return {'labels': vector}\n",
        "\n",
        "dataset = goEmotionsDataset.map(one_hot_encode)\n",
        "\n",
        "print(\"Original ID:\", goEmotionsDataset['train'][0]['labels'])\n",
        "print(\"New Vector:\", dataset['train'][0]['labels'])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SzZq9XyorwWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer\n",
        "from datasets import Sequence, Value\n",
        "\n",
        "# Tokenize and format for PyTorch\n",
        "def tokenize_text(rows):\n",
        "    return tokenizer(rows['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "tokenized_dataset = dataset.map(tokenize_text, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.cast_column(\"labels\", Sequence(Value(\"float32\")))\n",
        "tokenized_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iq3ZCdOQwP0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Set up F1 Score\n",
        "def compute_metrics(eval_pred):\n",
        "    threshold = 0.5\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    probs = 1 / (1 + np.exp(-logits))\n",
        "    predictions = (probs > threshold).astype(int)\n",
        "    return {'f1': f1_score(labels, predictions, average='micro'), 'precision': precision_score(labels, predictions, average='micro'), 'recall': recall_score(labels, predictions, average='micro')}\n"
      ],
      "metadata": {
        "id": "sn5DpGx0110y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roberta-sentiment-model\",\n",
        "    learning_rate=2e-5,             # How fast the model learns\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,             # Number of iterations through training\n",
        "    weight_decay=0.01,              # Regularization\n",
        "    eval_strategy=\"epoch\",          # Evaluate after each epoch\n",
        "    save_strategy=\"epoch\",          # Save the model after every epoch\n",
        "    load_best_model_at_end=True,    # Keep best version\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Train and Save\n",
        "trainer.train()\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "model_path = \"/content/drive/My Drive/RedditSentimentAnalysis/my_emotion_model\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)\n",
        "print(f\"Model successfully saved to: {model_path}\")"
      ],
      "metadata": {
        "id": "lwqD70rz2bu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import topk\n",
        "from transformers import pipeline\n",
        "\n",
        "# Use pipeline\n",
        "emotion_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./my_emotion_model\",\n",
        "    tokenizer=\"./my_emotion_model\"\n",
        ")\n",
        "\n",
        "# Test\n",
        "result = emotion_classifier(\"I HATE AI\", top_k=10)\n",
        "for prediction in result:\n",
        "    sentiment_id = int(prediction['label'].replace(\"LABEL_\", \"\"))\n",
        "    sentiment_name = goEmotionsDataset['train'].features['labels'].feature.names[sentiment_id]\n",
        "\n",
        "    print(f\"{sentiment_name}, Score: {prediction['score']}\")\n"
      ],
      "metadata": {
        "id": "i8iCYHfUBHwm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}