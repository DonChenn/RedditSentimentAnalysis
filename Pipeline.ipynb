{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAWJIRRW7_e0",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load classifier using roBERTa\n",
        "\n",
        "from transformers import pipeline\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_path = \"/content/drive/My Drive/RedditSentimentAnalysis/my_emotion_model\"\n",
        "\n",
        "emotion_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model_path,\n",
        "    tokenizer=model_path,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    topk=None\n",
        ")"
      ],
      "metadata": {
        "id": "uQH20nSUCQet",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"neelgajare/liberals-vs-conservatives-on-reddit-13000-posts\")\n",
        "\n",
        "csv_path = os.path.join(path, \"file_name.csv\")\n",
        "df = pd.read_csv(csv_path)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c8SwgBeYF_j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gets list of sentiments that are above threshold\n",
        "\n",
        "def get_sentiment(row_results):\n",
        "  top_sentiments = []\n",
        "  signal_threshold = 0.10\n",
        "\n",
        "  # List of dictionary {'label', 'score'}\n",
        "  for sentiment in row_results:\n",
        "\n",
        "    # Avoids Neutral as highest sentiment\n",
        "    if sentiment['label'] == 'neutral':\n",
        "        continue\n",
        "\n",
        "    elif sentiment['score'] >= signal_threshold:\n",
        "        top_sentiments.append(sentiment['label'])\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "  # If no sentiments met the threshold, return neutral\n",
        "  if top_sentiments:\n",
        "        return top_sentiments\n",
        "  else:\n",
        "      return ['neutral']\n",
        "\n",
        "\n",
        "def add_sentiment(df):\n",
        "  print(\"Filling empty strings in NAN data...\")\n",
        "  df['Title'] = df['Title'].fillna(\"\")\n",
        "  df['Text'] = df['Text'].fillna(\"\")\n",
        "\n",
        "  print(\"Preparing Title and Text inputs...\")\n",
        "  texts = (df[\"Title\"] + \" \" + df[\"Text\"]).tolist()\n",
        "\n",
        "  print(f\"Running classifier on {len(texts)} items...\")\n",
        "  raw_results = emotion_classifier(texts, batch_size=32, top_k=None)\n",
        "\n",
        "  print(\"Cleaning results...\")\n",
        "  clean_sentiments = [get_sentiment(r) for r in raw_results]\n",
        "\n",
        "  df['Sentiment'] = clean_sentiments\n"
      ],
      "metadata": {
        "id": "UVyBb2GpIV8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add sentiment column to Liberal vs Conservative Dataset\n",
        "\n",
        "add_sentiment(df)\n",
        "df.to_csv(\"sentiment_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "mdLBgYHCpe9-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GO_EMOTIONS_LABELS = [\n",
        "    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n",
        "    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n",
        "    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n",
        "    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n",
        "    \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n",
        "]\n",
        "\n",
        "label_map = {f\"LABEL_{i}\": label for i, label in enumerate(GO_EMOTIONS_LABELS)}\n",
        "\n",
        "\n",
        "df_exploded = df.explode('Sentiment')\n",
        "df_exploded['Sentiment_Name'] = df_exploded['Sentiment'].map(label_map)\n",
        "df_exploded['Sentiment_Name'].value_counts().plot(kind='bar', figsize=(12, 6), title=\"Reddit Sentiment Analysis\")"
      ],
      "metadata": {
        "id": "3wH4zY8jwKPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}